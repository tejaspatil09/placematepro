# -*- coding: utf-8 -*-
"""Placemate Pro Model Training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zXEqsQKKy9ofIVVuosyGSxt9xXYG6zQR

# **Placement Prediction**

## **1. Loading Data:**
"""

#importing required packages
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

#from google.colab import drive
#drive.mount('/content/drive')

# Loading the data
#path = '/content/drive/MyDrive/Datasets/placement.csv';

# Load csv file from local system
path = 'placement.csv';

# Read csv file
data = pd.read_csv(path)

# Read first 10 records
data.head(10)

"""## **2. Familiarizing with Data**"""

#Checking the shape of the dataset
data.shape

#Listing the features of the dataset
data.columns

# Check Information about the dataset
data.info()

"""## **3. Data Visualization**"""

# Plotting the data distribution
data.hist(bins = 20,figsize = (20,20))
plt.show()

# Ploting Correlation heatmap

plt.figure(figsize=(15,15))
sns.heatmap(data.corr(),annot = True)
plt.show()

"""## **4. Data Preprocessing & EDA**"""

# Checking description of the data in the DataFrame
data.describe()

#checking for null or missing values
data.isnull().sum()

"""## **5. Splitting the Data**"""

# Check the conditions and update columns values accrdingly
data['Placed'] = np.where(data['Placed'] > 49, 1, data['Placed'])
data['Placed'] = np.where(data['Placed'] != 1, 0, data['Placed'])
data.head(10)

# Filter records
X = data.iloc[:, :-1].values # get all records except last column
Y = data.iloc[:, -1].values # get only last column

print(X)

print(Y)

# Split dataset for model training and testing
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)
X_train.shape, X_test.shape

"""## **6. Machine Learning Models & Training**"""

# import and train RandomForestRegressor
from sklearn.ensemble import RandomForestRegressor
regressor = RandomForestRegressor(random_state=42, n_jobs=-1, max_depth=5, n_estimators=100, oob_score=True)
# regressor.fit(X_train, Y_train)

# Model Prediction
place_predict = regressor.fit(X_train, Y_train)

# Check prediction result
place_predict.predict([[100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100]])

"""## 7. Export Model"""

# Export model
import pickle as pk
file = pk.dump(place_predict, open('predictor.pickle', 'wb'))

# Import model and recheck the result
model = pk.load(open('predictor.pickle', 'rb'))
model.predict([[75,78,83,87,81,80,67,49,80,92,40,76,69,84,86,83]])
